services:
  kafka:
    image: apache/kafka:4.0.0      # Stable Apache Kafka image (no ZooKeeper; uses KRaft)
    container_name: kafka
    ports:
      - "9092:9092"                # Expose host-facing client port (we'll connect from your laptop to localhost:9092)
    environment:
      # --- Node identity & roles (KRaft single node) ---
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller

      # --- Controller quorum config (single-voter quorum for 1 node) ---
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9091

      # --- Listeners (define 3: controller, host, docker-internal) ---
      # CONTROLLER: internal metadata traffic (not used by clients)
      # HOST:       used by apps on your laptop (advertised as localhost:9092)
      # DOCKER:     used by *other containers* on the same docker network (e.g., Schema Registry)
      KAFKA_LISTENERS: CONTROLLER://0.0.0.0:9091,HOST://0.0.0.0:9092,DOCKER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: HOST://localhost:9092,DOCKER://kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,HOST:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: DOCKER

      # --- Required in Kafka 4.x so controller knows what to advertise ---
      KAFKA_CONTROLLER_ADVERTISED_LISTENERS: CONTROLLER://localhost:9091

      # --- Dev-friendly defaults (single node => replication factors = 1) ---
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"              # convenient for demos; disable in prod
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: "1"
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: "1"
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: "0"

      # --- Storage path inside container (we mount it to ./data) ---
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    volumes:
      - ./data:/var/lib/kafka/data

  schema-registry:
    image: confluentinc/cp-schema-registry:7.7.1  # Confluent's Schema Registry (works fine with Apache Kafka broker)
    container_name: schema-registry
    depends_on:
      - kafka                                     # wait for kafka to start
    ports:
      - "8081:8081"                               # expose REST API on localhost:8081 (we'll point clients here)
    environment:
      # REQUIRED: explicit hostname for the service
      SCHEMA_REGISTRY_HOST_NAME: "schema-registry"   # advertise this name; itâ€™s the container name

      # Tell Schema Registry how to reach Kafka (use the docker-internal listener we set up above)
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "PLAINTEXT://kafka:9093"

      # Bind the Schema Registry HTTP API to all interfaces (and expose 8081 above)
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"

  clickhouse:
    image: clickhouse/clickhouse-server:24.8   # pin version instead of 'latest' for repeatability
    container_name: clickhouse
    ports:
      - "8123:8123"   # HTTP interface (REST/SQL via HTTP)
      - "9000:9000"   # Native client (clickhouse-client, drivers)
    # Persist data & logs on the host so container restarts don't wipe your DB
    volumes:
      - ch_data:/var/lib/clickhouse
      - ch_logs:/var/log/clickhouse-server
    # using this config crashes my docker engine several seconds after running docker compose up
    # volumes:
    #   - ./clickhouse_data:/var/lib/clickhouse
    #   - ./clickhouse_logs:/var/log/clickhouse-server

      # OPTIONAL: run SQL on first init (e.g., create DB/tables). Only executed on a fresh data dir.
      - ./init_clickhouse.sql:/docker-entrypoint-initdb.d/init_clickhouse.sql:ro
    environment:
      - CLICKHOUSE_DB=demo            # or 'default' if you prefer
      - CLICKHOUSE_USER=default
      - CLICKHOUSE_PASSWORD=
    # Give ClickHouse enough file descriptors for busy workloads
    ulimits:
      nofile:
        soft: 262144
        hard: 262144

# optional, this is to explicitly define the volumns ch_data:/var/lib/clickhouse
volumes:
  ch_data:
  ch_logs:
